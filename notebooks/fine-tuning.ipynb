{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import load_dataset\n\n# Login using e.g. `huggingface-cli login` to access this dataset\nds = load_dataset(\"huyhamhoc/top4000\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-05T13:40:34.103929Z","iopub.execute_input":"2025-03-05T13:40:34.104276Z","iopub.status.idle":"2025-03-05T13:40:36.334948Z","shell.execute_reply.started":"2025-03-05T13:40:34.104250Z","shell.execute_reply":"2025-03-05T13:40:36.334112Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nnp_char_name = np.array(ds['train']['char_name'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T13:40:41.322317Z","iopub.execute_input":"2025-03-05T13:40:41.322725Z","iopub.status.idle":"2025-03-05T13:40:41.368514Z","shell.execute_reply.started":"2025-03-05T13:40:41.322685Z","shell.execute_reply":"2025-03-05T13:40:41.367598Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"unique_characters =np.unique(np_char_name)\ncharacter_to_label = {char: i for i, char in enumerate(unique_characters)}\ncharacter_to_label[ds['train']['char_name'][0]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T13:40:55.722908Z","iopub.execute_input":"2025-03-05T13:40:55.723233Z","iopub.status.idle":"2025-03-05T13:40:55.780187Z","shell.execute_reply.started":"2025-03-05T13:40:55.723209Z","shell.execute_reply":"2025-03-05T13:40:55.779368Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(unique_characters)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T13:40:58.465857Z","iopub.execute_input":"2025-03-05T13:40:58.466196Z","iopub.status.idle":"2025-03-05T13:40:58.471613Z","shell.execute_reply.started":"2025-03-05T13:40:58.466168Z","shell.execute_reply":"2025-03-05T13:40:58.470625Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport timm\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\nimport torchvision.transforms as transforms\nimport torch.optim.lr_scheduler as lr_scheduler\n\n\nclass AnimeDataset(Dataset):\n    def __init__(self, dataset, transform=None):\n        self.dataset = dataset\n        self.transform = transform\n        self.character_to_label = character_to_label\n\n    def __len__(self):\n        return len(self.dataset)\n\n    def __getitem__(self, idx):\n        # Lấy dữ liệu từ dataset\n        item = self.dataset[idx]\n        image = item[\"image\"]  # Giả sử image là một ảnh (không phải đường dẫn)\n        label = self.character_to_label[item[\"char_name\"]]  # Nhãn là tên nhân vật\n\n        if isinstance(image, str):  \n            image = Image.open(image).convert(\"RGB\")  # Chuyển sang RGB\n\n        # Nếu image không phải RGB, chuyển đổi nó\n        if image.mode != \"RGB\":\n            image = image.convert(\"RGB\")\n\n        # Áp dụng transform nếu có\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label\n\n    \n\n# Define transforms (e.g., resize, normalize)\ntransform_train = transforms.Compose([\n    # Biến đổi hình học\n    transforms.RandomRotation(20),              # Xoay ngẫu nhiên ±30 độ (mô phỏng góc quay đầu)\n    transforms.RandomHorizontalFlip(p=0.5),     # Lật ngang 50% (mô phỏng đối xứng khuôn mặt)\n    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # Cắt ngẫu nhiên và resize (mô phỏng zoom)\n\n    # Biến đổi màu sắc và ánh sáng\n    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),  # Thay đổi sáng, tương phản, bão hòa\n    transforms.RandomGrayscale(p=0.2),          # Chuyển thành ảnh xám 20% (mô phỏng điều kiện ánh sáng kém)\n    transforms.ToTensor(),\n\n    # Che khuất (occlusion) - mô phỏng vật cản trên khuôn mặt\n    transforms.RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.3, 3.3), value='random'),  # Xóa ngẫu nhiên một vùng\n\n    # Thêm nhiễu (noise)\n    transforms.Lambda(lambda img: img + torch.randn_like(img) * 0.1),  # Thêm nhiễu Gaussian nhẹ\n\n    # Chuẩn hóa\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Chuẩn hóa cho mô hình pre-trained\n])\ntransform_val = transforms.Compose([\n    transforms.Resize((224, 224)),                         # Resize về 224x224\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])    # Chuẩn hóa\n])\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T13:41:03.128705Z","iopub.execute_input":"2025-03-05T13:41:03.129041Z","iopub.status.idle":"2025-03-05T13:41:06.714937Z","shell.execute_reply.started":"2025-03-05T13:41:03.129019Z","shell.execute_reply":"2025-03-05T13:41:06.713858Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = AnimeDataset(ds['train'], transform=transform_train)\n\n# Kiểm tra số lượng mẫu\nprint(f\"Tổng số mẫu: {len(dataset)}\")\n\n# Lấy một mẫu kiểm tra\nimage, label = dataset[0]\nprint(f\"Loại dữ liệu image: {type(image)}\")\nprint(f\"Kích thước image: {image.shape if isinstance(image, torch.Tensor) else 'Không phải tensor'}\")\nprint(f\"Nhãn: {label}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T13:41:06.716173Z","iopub.execute_input":"2025-03-05T13:41:06.716444Z","iopub.status.idle":"2025-03-05T13:41:06.743238Z","shell.execute_reply.started":"2025-03-05T13:41:06.716421Z","shell.execute_reply":"2025-03-05T13:41:06.742382Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import random_split\n\n# Giả sử dataset có tổng số mẫu là N\ndataset = AnimeDataset(ds['train'], transform=transform_train)\ntotal_size = len(dataset)\n\n# Xác định tỉ lệ train/val, ví dụ 80% train, 20% val\ntrain_ratio = 0.8\ntrain_size = int(train_ratio * total_size)\nval_size = total_size - train_size  # Phần còn lại cho validation\n\n# Chia dataset\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\n# Kiểm tra kích thước\nprint(f\"Train size: {len(train_dataset)}, Val size: {len(val_dataset)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T13:41:07.771207Z","iopub.execute_input":"2025-03-05T13:41:07.771573Z","iopub.status.idle":"2025-03-05T13:41:07.780014Z","shell.execute_reply.started":"2025-03-05T13:41:07.771543Z","shell.execute_reply":"2025-03-05T13:41:07.779156Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import hashlib\nimport os\nimport shutil\nimport sys\nimport tempfile\n\nfrom urllib.request import urlopen, Request\n\ntry:\n    from tqdm.auto import tqdm  # automatically select proper tqdm submodule if available\nexcept ImportError:\n    from tqdm import tqdm\n\n\ndef download_url_to_file(url, dst, hash_prefix=None, progress=True):\n    r\"\"\"Download object at the given URL to a local path.\n    Args:\n        url (string): URL of the object to download\n        dst (string): Full path where object will be saved, e.g. `/tmp/temporary_file`\n        hash_prefix (string, optional): If not None, the SHA256 downloaded file should start with `hash_prefix`.\n            Default: None\n        progress (bool, optional): whether or not to display a progress bar to stderr\n            Default: True\n    Example:\n        >>> torch.hub.download_url_to_file('https://s3.amazonaws.com/pytorch/models/resnet18-5c106cde.pth', '/tmp/temporary_file')\n    \"\"\"\n    file_size = None\n    # We use a different API for python2 since urllib(2) doesn't recognize the CA\n    # certificates in older Python\n    req = Request(url, headers={\"User-Agent\": \"torch.hub\"})\n    u = urlopen(req)\n    meta = u.info()\n    if hasattr(meta, 'getheaders'):\n        content_length = meta.getheaders(\"Content-Length\")\n    else:\n        content_length = meta.get_all(\"Content-Length\")\n    if content_length is not None and len(content_length) > 0:\n        file_size = int(content_length[0])\n\n    # We deliberately save it in a temp file and move it after\n    # download is complete. This prevents a local working checkpoint\n    # being overridden by a broken download.\n    dst = os.path.expanduser(dst)\n    dst_dir = os.path.dirname(dst)\n    f = tempfile.NamedTemporaryFile(delete=False, dir=dst_dir)\n\n    try:\n        if hash_prefix is not None:\n            sha256 = hashlib.sha256()\n        with tqdm(total=file_size, disable=not progress,\n                  unit='B', unit_scale=True, unit_divisor=1024) as pbar:\n            while True:\n                buffer = u.read(8192)\n                if len(buffer) == 0:\n                    break\n                f.write(buffer)\n                if hash_prefix is not None:\n                    sha256.update(buffer)\n                pbar.update(len(buffer))\n\n        f.close()\n        if hash_prefix is not None:\n            digest = sha256.hexdigest()\n            if digest[:len(hash_prefix)] != hash_prefix:\n                raise RuntimeError('invalid hash value (expected \"{}\", got \"{}\")'\n                                   .format(hash_prefix, digest))\n        shutil.move(f.name, dst)\n    finally:\n        f.close()\n        if os.path.exists(f.name):\n            os.remove(f.name)\n\n\nimport os\nimport requests\nfrom requests.adapters import HTTPAdapter\n\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\n\n\n\nclass BasicConv2d(nn.Module):\n\n    def __init__(self, in_planes, out_planes, kernel_size, stride, padding=0):\n        super().__init__()\n        self.conv = nn.Conv2d(\n            in_planes, out_planes,\n            kernel_size=kernel_size, stride=stride,\n            padding=padding, bias=False\n        ) # verify bias false\n        self.bn = nn.BatchNorm2d(\n            out_planes,\n            eps=0.001, # value found in tensorflow\n            momentum=0.1, # default pytorch value\n            affine=True\n        )\n        self.relu = nn.ReLU(inplace=False)\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = self.relu(x)\n        return x\n\n\nclass Block35(nn.Module):\n\n    def __init__(self, scale=1.0):\n        super().__init__()\n\n        self.scale = scale\n\n        self.branch0 = BasicConv2d(256, 32, kernel_size=1, stride=1)\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(256, 32, kernel_size=1, stride=1),\n            BasicConv2d(32, 32, kernel_size=3, stride=1, padding=1)\n        )\n\n        self.branch2 = nn.Sequential(\n            BasicConv2d(256, 32, kernel_size=1, stride=1),\n            BasicConv2d(32, 32, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(32, 32, kernel_size=3, stride=1, padding=1)\n        )\n\n        self.conv2d = nn.Conv2d(96, 256, kernel_size=1, stride=1)\n        self.relu = nn.ReLU(inplace=False)\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        x2 = self.branch2(x)\n        out = torch.cat((x0, x1, x2), 1)\n        out = self.conv2d(out)\n        out = out * self.scale + x\n        out = self.relu(out)\n        return out\n\n\nclass Block17(nn.Module):\n\n    def __init__(self, scale=1.0):\n        super().__init__()\n\n        self.scale = scale\n\n        self.branch0 = BasicConv2d(896, 128, kernel_size=1, stride=1)\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(896, 128, kernel_size=1, stride=1),\n            BasicConv2d(128, 128, kernel_size=(1,7), stride=1, padding=(0,3)),\n            BasicConv2d(128, 128, kernel_size=(7,1), stride=1, padding=(3,0))\n        )\n\n        self.conv2d = nn.Conv2d(256, 896, kernel_size=1, stride=1)\n        self.relu = nn.ReLU(inplace=False)\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        out = torch.cat((x0, x1), 1)\n        out = self.conv2d(out)\n        out = out * self.scale + x\n        out = self.relu(out)\n        return out\n\n\nclass Block8(nn.Module):\n\n    def __init__(self, scale=1.0, noReLU=False):\n        super().__init__()\n\n        self.scale = scale\n        self.noReLU = noReLU\n\n        self.branch0 = BasicConv2d(1792, 192, kernel_size=1, stride=1)\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(1792, 192, kernel_size=1, stride=1),\n            BasicConv2d(192, 192, kernel_size=(1,3), stride=1, padding=(0,1)),\n            BasicConv2d(192, 192, kernel_size=(3,1), stride=1, padding=(1,0))\n        )\n\n        self.conv2d = nn.Conv2d(384, 1792, kernel_size=1, stride=1)\n        if not self.noReLU:\n            self.relu = nn.ReLU(inplace=False)\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        out = torch.cat((x0, x1), 1)\n        out = self.conv2d(out)\n        out = out * self.scale + x\n        if not self.noReLU:\n            out = self.relu(out)\n        return out\n\n\nclass Mixed_6a(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n\n        self.branch0 = BasicConv2d(256, 384, kernel_size=3, stride=2)\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(256, 192, kernel_size=1, stride=1),\n            BasicConv2d(192, 192, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(192, 256, kernel_size=3, stride=2)\n        )\n\n        self.branch2 = nn.MaxPool2d(3, stride=2)\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        x2 = self.branch2(x)\n        out = torch.cat((x0, x1, x2), 1)\n        return out\n\n\nclass Mixed_7a(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n\n        self.branch0 = nn.Sequential(\n            BasicConv2d(896, 256, kernel_size=1, stride=1),\n            BasicConv2d(256, 384, kernel_size=3, stride=2)\n        )\n\n        self.branch1 = nn.Sequential(\n            BasicConv2d(896, 256, kernel_size=1, stride=1),\n            BasicConv2d(256, 256, kernel_size=3, stride=2)\n        )\n\n        self.branch2 = nn.Sequential(\n            BasicConv2d(896, 256, kernel_size=1, stride=1),\n            BasicConv2d(256, 256, kernel_size=3, stride=1, padding=1),\n            BasicConv2d(256, 256, kernel_size=3, stride=2)\n        )\n\n        self.branch3 = nn.MaxPool2d(3, stride=2)\n\n    def forward(self, x):\n        x0 = self.branch0(x)\n        x1 = self.branch1(x)\n        x2 = self.branch2(x)\n        x3 = self.branch3(x)\n        out = torch.cat((x0, x1, x2, x3), 1)\n        return out\n\n\nclass InceptionResnetV1(nn.Module):\n    \"\"\"Inception Resnet V1 model with optional loading of pretrained weights.\n\n    Model parameters can be loaded based on pretraining on the VGGFace2 or CASIA-Webface\n    datasets. Pretrained state_dicts are automatically downloaded on model instantiation if\n    requested and cached in the torch cache. Subsequent instantiations use the cache rather than\n    redownloading.\n\n    Keyword Arguments:\n        pretrained {str} -- Optional pretraining dataset. Either 'vggface2' or 'casia-webface'.\n            (default: {None})\n        classify {bool} -- Whether the model should output classification probabilities or feature\n            embeddings. (default: {False})\n        num_classes {int} -- Number of output classes. If 'pretrained' is set and num_classes not\n            equal to that used for the pretrained model, the final linear layer will be randomly\n            initialized. (default: {None})\n        dropout_prob {float} -- Dropout probability. (default: {0.6})\n    \"\"\"\n    def __init__(self, pretrained=None, classify=False, num_classes=None, dropout_prob=0.6, device=None):\n        super().__init__()\n\n        # Set simple attributes\n        self.pretrained = pretrained\n        self.classify = classify\n        self.num_classes = num_classes\n\n        if pretrained == 'vggface2':\n            tmp_classes = 8631\n        elif pretrained == 'casia-webface':\n            tmp_classes = 10575\n        elif pretrained is None and self.classify and self.num_classes is None:\n            raise Exception('If \"pretrained\" is not specified and \"classify\" is True, \"num_classes\" must be specified')\n\n\n        # Define layers\n        self.conv2d_1a = BasicConv2d(3, 32, kernel_size=3, stride=2)\n        self.conv2d_2a = BasicConv2d(32, 32, kernel_size=3, stride=1)\n        self.conv2d_2b = BasicConv2d(32, 64, kernel_size=3, stride=1, padding=1)\n        self.maxpool_3a = nn.MaxPool2d(3, stride=2)\n        self.conv2d_3b = BasicConv2d(64, 80, kernel_size=1, stride=1)\n        self.conv2d_4a = BasicConv2d(80, 192, kernel_size=3, stride=1)\n        self.conv2d_4b = BasicConv2d(192, 256, kernel_size=3, stride=2)\n        self.repeat_1 = nn.Sequential(\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n            Block35(scale=0.17),\n        )\n        self.mixed_6a = Mixed_6a()\n        self.repeat_2 = nn.Sequential(\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n            Block17(scale=0.10),\n        )\n        self.mixed_7a = Mixed_7a()\n        self.repeat_3 = nn.Sequential(\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n            Block8(scale=0.20),\n        )\n        self.block8 = Block8(noReLU=True)\n        self.avgpool_1a = nn.AdaptiveAvgPool2d(1)\n        self.dropout = nn.Dropout(dropout_prob)\n        self.last_linear = nn.Linear(1792, 512, bias=False)\n        self.last_bn = nn.BatchNorm1d(512, eps=0.001, momentum=0.1, affine=True)\n\n        if pretrained is not None:\n            self.logits = nn.Linear(512, tmp_classes)\n            load_weights(self, pretrained)\n\n        if self.classify and self.num_classes is not None:\n            self.logits = nn.Linear(512, self.num_classes)\n\n        self.device = torch.device('cpu')\n        if device is not None:\n            self.device = device\n            self.to(device)\n\n    def forward(self, x):\n        \"\"\"Calculate embeddings or logits given a batch of input image tensors.\n\n        Arguments:\n            x {torch.tensor} -- Batch of image tensors representing faces.\n\n        Returns:\n            torch.tensor -- Batch of embedding vectors or multinomial logits.\n        \"\"\"\n        x = self.conv2d_1a(x)\n        x = self.conv2d_2a(x)\n        x = self.conv2d_2b(x)\n        x = self.maxpool_3a(x)\n        x = self.conv2d_3b(x)\n        x = self.conv2d_4a(x)\n        x = self.conv2d_4b(x)\n        x = self.repeat_1(x)\n        x = self.mixed_6a(x)\n        x = self.repeat_2(x)\n        x = self.mixed_7a(x)\n        x = self.repeat_3(x)\n        x = self.block8(x)\n        x = self.avgpool_1a(x)\n        x = self.dropout(x)\n        x = self.last_linear(x.view(x.shape[0], -1))\n        x = self.last_bn(x)\n        if self.classify:\n            x = self.logits(x)\n        else:\n            x = F.normalize(x, p=2, dim=1)\n        return x\n\n\ndef load_weights(mdl, name):\n    \"\"\"Download pretrained state_dict and load into model.\n\n    Arguments:\n        mdl {torch.nn.Module} -- Pytorch model.\n        name {str} -- Name of dataset that was used to generate pretrained state_dict.\n\n    Raises:\n        ValueError: If 'pretrained' not equal to 'vggface2' or 'casia-webface'.\n    \"\"\"\n    if name == 'vggface2':\n        path = 'https://github.com/timesler/facenet-pytorch/releases/download/v2.2.9/20180402-114759-vggface2.pt'\n    elif name == 'casia-webface':\n        path = 'https://github.com/timesler/facenet-pytorch/releases/download/v2.2.9/20180408-102900-casia-webface.pt'\n    else:\n        raise ValueError('Pretrained models only exist for \"vggface2\" and \"casia-webface\"')\n\n    model_dir = os.path.join(get_torch_home(), 'checkpoints')\n    os.makedirs(model_dir, exist_ok=True)\n\n    cached_file = os.path.join(model_dir, os.path.basename(path))\n    if not os.path.exists(cached_file):\n        download_url_to_file(path, cached_file)\n\n    state_dict = torch.load(cached_file)\n    mdl.load_state_dict(state_dict)\n\n\ndef get_torch_home():\n    torch_home = os.path.expanduser(\n        os.getenv(\n            'TORCH_HOME',\n            os.path.join(os.getenv('XDG_CACHE_HOME', '~/.cache'), 'torch')\n        )\n    )\n    return torch_home","metadata":{"trusted":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2025-03-05T13:41:11.101000Z","iopub.execute_input":"2025-03-05T13:41:11.101306Z","iopub.status.idle":"2025-03-05T13:41:11.326300Z","shell.execute_reply.started":"2025-03-05T13:41:11.101282Z","shell.execute_reply":"2025-03-05T13:41:11.325447Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.optim import lr_scheduler\n\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n\n# Khởi tạo mô hình\nmodel = InceptionResnetV1(pretrained='vggface2')\nnum_classes = len(unique_characters)  # Số lượng nhân vật duy nhất trong tập dữ liệu của bạn\nmodel.classify = True  # Kích hoạt lớp phân loại\n\n# Thay đổi lớp logits\nmodel.logits = nn.Linear(model.logits.in_features, num_classes)\n\n# Khởi tạo criterion, optimizer, và scheduler\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.0005)\nscheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)  # Điều chỉnh T_max cho phù hợp với số epoch\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\n\nnum_epochs = 15\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    top5_correct = 0\n\n    # Huấn luyện\n    for images, labels in train_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n\n        # Đặt lại gradient\n        optimizer.zero_grad()\n\n        # Forward pass\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        # Backward pass và tối ưu hóa\n        loss.backward()\n        optimizer.step()\n\n        # Tích lũy loss và accuracy\n        running_loss += loss.item()\n        _, predicted = torch.max(outputs.data, 1)  # Dự đoán lớp cho top-1 accuracy\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()  # Tính số lượng dự đoán chính xác cho top-1\n\n        # Tính top-5 accuracy\n        top5_pred = torch.topk(outputs, 5, dim=1).indices  # Lấy 5 nhãn dự đoán có xác suất cao nhất\n        for i in range(labels.size(0)):\n            if labels[i] in top5_pred[i]:\n                top5_correct += 1  # Nếu nhãn thực nằm trong top 5 dự đoán, tăng biến đếm\n\n    \n    \n    # Tính toán accuracy trong quá trình huấn luyện\n    train_accuracy = correct / total * 100  # Tính accuracy theo phần trăm\n    train_top5_accuracy = top5_correct / total * 100  # Tính top-5 accuracy theo phần trăm\n    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {running_loss/len(train_loader):.4f}, \"\n          f\"Train Accuracy: {train_accuracy:.2f}%, Train Top-5 Accuracy: {train_top5_accuracy:.2f}%\")\n\n    # Validation\n    model.eval()  # Chuyển mô hình sang chế độ đánh giá\n    val_loss = 0.0\n    val_correct = 0\n    val_total = 0\n    val_top5_correct = 0\n\n    with torch.no_grad():  # Không tính gradient trong quá trình validation\n        for images, labels in val_loader:\n            images = images.to(device)\n            labels = labels.to(device)\n            # Forward pass\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            # Tích lũy validation loss\n            val_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)  # Dự đoán lớp cho top-1 accuracy\n            val_total += labels.size(0)\n            val_correct += (predicted == labels).sum().item()  # Tính số lượng dự đoán chính xác cho top-1\n\n            # Tính top-5 accuracy\n            top5_pred = torch.topk(outputs, 5, dim=1).indices  # Lấy 5 nhãn dự đoán có xác suất cao nhất\n            for i in range(labels.size(0)):\n                if labels[i] in top5_pred[i]:\n                    val_top5_correct += 1  # Nếu nhãn thực nằm trong top 5 dự đoán, tăng biến đếm\n\n    # Tính toán accuracy trong validation\n    val_accuracy = val_correct / val_total * 100  # Tính accuracy theo phần trăm\n    val_top5_accuracy = val_top5_correct / val_total * 100  # Tính top-5 accuracy theo phần trăm\n    print(f\"Validation Loss: {val_loss/len(val_loader):.4f}, Validation Accuracy: {val_accuracy:.2f}%, \"\n          f\"Validation Top-5 Accuracy: {val_top5_accuracy:.2f}%\")\n\n    scheduler.step()\nprint(\"Fine-tuning complete.\")\nmodel.classify = False\ntorch.save(model,'fine_tuned_facenet.pth')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T13:41:22.381171Z","iopub.execute_input":"2025-03-05T13:41:22.381510Z","iopub.status.idle":"2025-03-05T15:05:45.599656Z","shell.execute_reply.started":"2025-03-05T13:41:22.381486Z","shell.execute_reply":"2025-03-05T15:05:45.598035Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}